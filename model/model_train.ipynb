{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbSkt0e0WqYZ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob"
      ],
      "metadata": {
        "id": "ctkK4y8aXIm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets from a folder\n",
        "path = 'cleandata/'  # specify your folder path\n",
        "all_files = glob.glob(path + \"*.csv\")  # finds all csv files in the folder\n",
        "\n",
        "# Read each CSV file and concatenate them into one DataFrame\n",
        "data = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
        "\n",
        "# Combine columns into a single text per row, handling missing values\n",
        "todo_texts = data.apply(lambda x: ' '.join(x.dropna().values.tolist()), axis=1)"
      ],
      "metadata": {
        "id": "o5iulaeBXKOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "todo_texts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_0ElNKFX8Rw",
        "outputId": "63aaa2b5-5eb8-44e7-dafd-f4797e3962a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           Call name to discuss project details at time\n",
              "1                        Water the plants in the morning\n",
              "2           Grocery shopping at the local market at time\n",
              "3                   Cancel gym membership over the phone\n",
              "4        Prepare presentation slides for Mondays meeting\n",
              "                              ...                       \n",
              "19325                      Implement new morning routine\n",
              "19326                        Attend friend's art exhibit\n",
              "19327                               Purchase houseplants\n",
              "19328                           File important documents\n",
              "19329                            Back up smartphone data\n",
              "Length: 19330, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(todo_texts)\n",
        "sequences = tokenizer.texts_to_sequences(todo_texts)\n",
        "\n",
        "# Create input sequences\n",
        "input_sequences = []\n",
        "for sequence in sequences:\n",
        "    for i in range(1, len(sequence)):\n",
        "        input_sequences.append(sequence[:i+1])\n",
        "\n",
        "max_sequence_len = max(len(x) for x in input_sequences)\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n"
      ],
      "metadata": {
        "id": "YEaBstojYC_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNfrSQRdY7WI",
        "outputId": "37760663-b371-43ef-fe7b-dbfe1d4d5da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(input_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iysqiYSFYDAf",
        "outputId": "f781d0e8-3aa4-46c1-bd60-d6cc94bfd8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "106805"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictors and label\n",
        "predictors, label = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "label = to_categorical(label, num_classes=len(tokenizer.word_index) + 1)\n",
        "\n",
        "# Model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=10, input_length=max_sequence_len - 1),\n",
        "    LSTM(100),\n",
        "    Dense(len(tokenizer.word_index) + 1, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "UGt31z1bZE5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(predictors, label, epochs=50, verbose=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpX2KPoLZOPQ",
        "outputId": "238841b2-a348-420a-b43e-1a14f3c528ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3338/3338 [==============================] - 146s 44ms/step - loss: 5.3498 - accuracy: 0.1295\n",
            "Epoch 2/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 4.5043 - accuracy: 0.2141\n",
            "Epoch 3/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 3.9925 - accuracy: 0.2732\n",
            "Epoch 4/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 3.6264 - accuracy: 0.3160\n",
            "Epoch 5/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 3.3492 - accuracy: 0.3471\n",
            "Epoch 6/50\n",
            "3338/3338 [==============================] - 147s 44ms/step - loss: 3.1348 - accuracy: 0.3725\n",
            "Epoch 7/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 2.9649 - accuracy: 0.3915\n",
            "Epoch 8/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 2.8264 - accuracy: 0.4070\n",
            "Epoch 9/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 2.7102 - accuracy: 0.4211\n",
            "Epoch 10/50\n",
            "3338/3338 [==============================] - 145s 44ms/step - loss: 2.6112 - accuracy: 0.4333\n",
            "Epoch 11/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 2.5248 - accuracy: 0.4426\n",
            "Epoch 12/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 2.4505 - accuracy: 0.4525\n",
            "Epoch 13/50\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 2.3847 - accuracy: 0.4625\n",
            "Epoch 14/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 2.3269 - accuracy: 0.4700\n",
            "Epoch 15/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 2.2749 - accuracy: 0.4770\n",
            "Epoch 16/50\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 2.2276 - accuracy: 0.4830\n",
            "Epoch 17/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 2.1836 - accuracy: 0.4889\n",
            "Epoch 18/50\n",
            "3338/3338 [==============================] - 142s 43ms/step - loss: 2.1445 - accuracy: 0.4967\n",
            "Epoch 19/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 2.1090 - accuracy: 0.5016\n",
            "Epoch 20/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 2.0758 - accuracy: 0.5064\n",
            "Epoch 21/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 2.0465 - accuracy: 0.5103\n",
            "Epoch 22/50\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 2.0160 - accuracy: 0.5166\n",
            "Epoch 23/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.9899 - accuracy: 0.5197\n",
            "Epoch 24/50\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 1.9657 - accuracy: 0.5247\n",
            "Epoch 25/50\n",
            "3338/3338 [==============================] - 142s 43ms/step - loss: 1.9423 - accuracy: 0.5284\n",
            "Epoch 26/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.9205 - accuracy: 0.5318\n",
            "Epoch 27/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.9001 - accuracy: 0.5353\n",
            "Epoch 28/50\n",
            "3338/3338 [==============================] - 142s 43ms/step - loss: 1.8800 - accuracy: 0.5399\n",
            "Epoch 29/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.8624 - accuracy: 0.5405\n",
            "Epoch 30/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.8455 - accuracy: 0.5450\n",
            "Epoch 31/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.8282 - accuracy: 0.5477\n",
            "Epoch 32/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.8126 - accuracy: 0.5500\n",
            "Epoch 33/50\n",
            "3338/3338 [==============================] - 146s 44ms/step - loss: 1.7977 - accuracy: 0.5521\n",
            "Epoch 34/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.7854 - accuracy: 0.5545\n",
            "Epoch 35/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.7714 - accuracy: 0.5574\n",
            "Epoch 36/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.7586 - accuracy: 0.5579\n",
            "Epoch 37/50\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 1.7461 - accuracy: 0.5626\n",
            "Epoch 38/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.7352 - accuracy: 0.5642\n",
            "Epoch 39/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.7248 - accuracy: 0.5656\n",
            "Epoch 40/50\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 1.7126 - accuracy: 0.5684\n",
            "Epoch 41/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.7034 - accuracy: 0.5684\n",
            "Epoch 42/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.6925 - accuracy: 0.5708\n",
            "Epoch 43/50\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 1.6831 - accuracy: 0.5733\n",
            "Epoch 44/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.6751 - accuracy: 0.5748\n",
            "Epoch 45/50\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.6658 - accuracy: 0.5774\n",
            "Epoch 46/50\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 1.6576 - accuracy: 0.5779\n",
            "Epoch 47/50\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 1.6502 - accuracy: 0.5789\n",
            "Epoch 48/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.6418 - accuracy: 0.5801\n",
            "Epoch 49/50\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.6352 - accuracy: 0.5820\n",
            "Epoch 50/50\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 1.6266 - accuracy: 0.5829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b53c034cbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(predictors, label, epochs=80, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-kP2kBUguMP",
        "outputId": "98827d21-b76a-4580-a08e-d84b9753d81d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "3338/3338 [==============================] - 146s 44ms/step - loss: 1.6193 - accuracy: 0.5853\n",
            "Epoch 2/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.6134 - accuracy: 0.5854\n",
            "Epoch 3/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.6061 - accuracy: 0.5878\n",
            "Epoch 4/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.6007 - accuracy: 0.5889\n",
            "Epoch 5/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.5941 - accuracy: 0.5894\n",
            "Epoch 6/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.5884 - accuracy: 0.5909\n",
            "Epoch 7/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.5828 - accuracy: 0.5904\n",
            "Epoch 8/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.5759 - accuracy: 0.5933\n",
            "Epoch 9/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.5704 - accuracy: 0.5953\n",
            "Epoch 10/80\n",
            "3338/3338 [==============================] - 142s 43ms/step - loss: 1.5650 - accuracy: 0.5945\n",
            "Epoch 11/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.5592 - accuracy: 0.5962\n",
            "Epoch 12/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.5575 - accuracy: 0.5954\n",
            "Epoch 13/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.5501 - accuracy: 0.5964\n",
            "Epoch 14/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.5476 - accuracy: 0.5967\n",
            "Epoch 15/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.5419 - accuracy: 0.5999\n",
            "Epoch 16/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.5385 - accuracy: 0.5994\n",
            "Epoch 17/80\n",
            "3338/3338 [==============================] - 145s 44ms/step - loss: 1.5322 - accuracy: 0.6007\n",
            "Epoch 18/80\n",
            "3338/3338 [==============================] - 142s 43ms/step - loss: 1.5299 - accuracy: 0.6009\n",
            "Epoch 19/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.5227 - accuracy: 0.6028\n",
            "Epoch 20/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.5207 - accuracy: 0.6029\n",
            "Epoch 21/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.5169 - accuracy: 0.6028\n",
            "Epoch 22/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.5122 - accuracy: 0.6041\n",
            "Epoch 23/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.5094 - accuracy: 0.6046\n",
            "Epoch 24/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.5055 - accuracy: 0.6061\n",
            "Epoch 25/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.5017 - accuracy: 0.6058\n",
            "Epoch 26/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4996 - accuracy: 0.6067\n",
            "Epoch 27/80\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 1.4930 - accuracy: 0.6073\n",
            "Epoch 28/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4929 - accuracy: 0.6071\n",
            "Epoch 29/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4886 - accuracy: 0.6078\n",
            "Epoch 30/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4856 - accuracy: 0.6084\n",
            "Epoch 31/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4859 - accuracy: 0.6073\n",
            "Epoch 32/80\n",
            "3338/3338 [==============================] - 145s 44ms/step - loss: 1.4778 - accuracy: 0.6101\n",
            "Epoch 33/80\n",
            "3338/3338 [==============================] - 142s 42ms/step - loss: 1.4788 - accuracy: 0.6094\n",
            "Epoch 34/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4726 - accuracy: 0.6107\n",
            "Epoch 35/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4701 - accuracy: 0.6116\n",
            "Epoch 36/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4698 - accuracy: 0.6104\n",
            "Epoch 37/80\n",
            "3338/3338 [==============================] - 146s 44ms/step - loss: 1.4636 - accuracy: 0.6129\n",
            "Epoch 38/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4633 - accuracy: 0.6128\n",
            "Epoch 39/80\n",
            "3338/3338 [==============================] - 142s 43ms/step - loss: 1.4594 - accuracy: 0.6138\n",
            "Epoch 40/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4582 - accuracy: 0.6135\n",
            "Epoch 41/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4542 - accuracy: 0.6143\n",
            "Epoch 42/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4516 - accuracy: 0.6148\n",
            "Epoch 43/80\n",
            "3338/3338 [==============================] - 141s 42ms/step - loss: 1.4499 - accuracy: 0.6164\n",
            "Epoch 44/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4495 - accuracy: 0.6148\n",
            "Epoch 45/80\n",
            "3338/3338 [==============================] - 150s 45ms/step - loss: 1.4486 - accuracy: 0.6150\n",
            "Epoch 46/80\n",
            "3338/3338 [==============================] - 150s 45ms/step - loss: 1.4446 - accuracy: 0.6157\n",
            "Epoch 47/80\n",
            "3338/3338 [==============================] - 153s 46ms/step - loss: 1.4500 - accuracy: 0.6137\n",
            "Epoch 48/80\n",
            "3338/3338 [==============================] - 151s 45ms/step - loss: 1.4400 - accuracy: 0.6168\n",
            "Epoch 49/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4401 - accuracy: 0.6165\n",
            "Epoch 50/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4397 - accuracy: 0.6163\n",
            "Epoch 51/80\n",
            "3338/3338 [==============================] - 142s 43ms/step - loss: 1.4364 - accuracy: 0.6183\n",
            "Epoch 52/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4342 - accuracy: 0.6173\n",
            "Epoch 53/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4314 - accuracy: 0.6188\n",
            "Epoch 54/80\n",
            "3338/3338 [==============================] - 145s 43ms/step - loss: 1.4324 - accuracy: 0.6178\n",
            "Epoch 55/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4282 - accuracy: 0.6181\n",
            "Epoch 56/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4254 - accuracy: 0.6191\n",
            "Epoch 57/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4233 - accuracy: 0.6204\n",
            "Epoch 58/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4237 - accuracy: 0.6204\n",
            "Epoch 59/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4260 - accuracy: 0.6186\n",
            "Epoch 60/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4177 - accuracy: 0.6211\n",
            "Epoch 61/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4140 - accuracy: 0.6229\n",
            "Epoch 62/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4146 - accuracy: 0.6205\n",
            "Epoch 63/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4264 - accuracy: 0.6181\n",
            "Epoch 64/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4094 - accuracy: 0.6233\n",
            "Epoch 65/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4057 - accuracy: 0.6228\n",
            "Epoch 66/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4065 - accuracy: 0.6217\n",
            "Epoch 67/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4620 - accuracy: 0.6097\n",
            "Epoch 68/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4538 - accuracy: 0.6112\n",
            "Epoch 69/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4273 - accuracy: 0.6168\n",
            "Epoch 70/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4463 - accuracy: 0.6192\n",
            "Epoch 71/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4142 - accuracy: 0.6199\n",
            "Epoch 72/80\n",
            "3338/3338 [==============================] - 142s 43ms/step - loss: 1.4112 - accuracy: 0.6205\n",
            "Epoch 73/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4088 - accuracy: 0.6201\n",
            "Epoch 74/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4061 - accuracy: 0.6214\n",
            "Epoch 75/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4060 - accuracy: 0.6207\n",
            "Epoch 76/80\n",
            "3338/3338 [==============================] - 144s 43ms/step - loss: 1.4062 - accuracy: 0.6207\n",
            "Epoch 77/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4015 - accuracy: 0.6217\n",
            "Epoch 78/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.4031 - accuracy: 0.6222\n",
            "Epoch 79/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.3976 - accuracy: 0.6220\n",
            "Epoch 80/80\n",
            "3338/3338 [==============================] - 143s 43ms/step - loss: 1.3984 - accuracy: 0.6231\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b53c0391e40>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction function\n",
        "def predict_next_words(model, tokenizer, text, num_words=3):\n",
        "    for _ in range(num_words):\n",
        "        sequence = tokenizer.texts_to_sequences([text])[0]\n",
        "        padded_sequence = pad_sequences([sequence], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predictions = model.predict(padded_sequence)[0]\n",
        "        predicted_word_indices = np.argsort(predictions)[-num_words:]\n",
        "        for idx in predicted_word_indices:\n",
        "            output_word = tokenizer.index_word.get(idx, '')\n",
        "            print(output_word)"
      ],
      "metadata": {
        "id": "8jgwU_hoZQ5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_words(model,tokenizer,\"have a meeting with\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WHCe5DhowY5",
        "outputId": "81938db4-ca9a-4544-89f0-fb44ce5cd2c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "potential\n",
            "a\n",
            "name\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "potential\n",
            "a\n",
            "name\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "potential\n",
            "a\n",
            "name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_words(model, tokenizer, text, num_words=15):\n",
        "    current_text = text\n",
        "    for _ in range(num_words):\n",
        "        sequence = tokenizer.texts_to_sequences([current_text])[0]\n",
        "        padded_sequence = pad_sequences([sequence], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predictions = model.predict(padded_sequence)[0]\n",
        "        next_word_index = np.argmax(predictions)\n",
        "        next_word = tokenizer.index_word.get(next_word_index, '')\n",
        "        current_text += ' ' + next_word\n",
        "        print(next_word)\n"
      ],
      "metadata": {
        "id": "zYb2pHhTp0sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_next_words(model,tokenizer,\"buy\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSxlXgAsp1Qh",
        "outputId": "ca915eb0-9f2a-432d-bdc3-2bcec46ae3de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 28ms/step\n",
            "a\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "new\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "charger\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "for\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "the\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "laptop\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "next\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "month\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "and\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "adjust\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "on\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "app\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "for\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "next\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "month\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVzqD8fxqV3G",
        "outputId": "0e8b973e-5098-43a7-ac96-f816de0d7422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存模型为 Keras 推荐的格式\n",
        "model.save('my_model.keras')\n"
      ],
      "metadata": {
        "id": "WWtNtdkvqf_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('tokenizer.pkl', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "d06D0YtPqgws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}